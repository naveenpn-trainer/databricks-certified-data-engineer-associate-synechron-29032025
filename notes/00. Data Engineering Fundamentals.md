# Data Engineering Fundamentals

> Big Data refers to the data which is **large, fast** and complex type of **structured, semi-structured and unstructured data** generated from variety of different sources, which becomes difficult to store and process using a traditional processing system

**Two challenges**

1. Storage : Distributed Storage System
2. Processing : MPP (Massive Parallel Processing Framework)

## Hadoop (Distributed Storage and Proce)

> Apache Hadoop is a software framework that allows us to store and processing large datasets in parallel and distributed fashion

Hadoop provides 3 components

1. Storage Layer : HDFS (Hadoop Distribtued FS)
2. Resource Management Layer : YARN (Yet Another Resource Negotiator)
3. Processing : MapReduce

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcEkONzLzsXwc7cCcSed4OgAekz4FdFzEGIR1j4zMQphDQ8GhAv-9hnof0pmJjgcgLCzQRuTonKyipZweFHhRhnBOyCW9o41Oa-aoJaKPkUuB4B4fF_SkzbF8UYXTHejr34MwXWSbEbTe7K3TsEkr6FOFUQ?key=Lcjgu0sLjm8U8i3A_14gRg)

